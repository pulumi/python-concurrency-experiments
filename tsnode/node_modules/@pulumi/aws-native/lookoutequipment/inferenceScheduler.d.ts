import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";
import * as enums from "../types/enums";
/**
 * Resource schema for LookoutEquipment InferenceScheduler.
 *
 * @deprecated InferenceScheduler is not yet supported by AWS Native, so its creation will currently fail. Please use the classic AWS provider, if possible.
 */
export declare class InferenceScheduler extends pulumi.CustomResource {
    /**
     * Get an existing InferenceScheduler resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    static get(name: string, id: pulumi.Input<pulumi.ID>, opts?: pulumi.CustomResourceOptions): InferenceScheduler;
    /**
     * Returns true if the given object is an instance of InferenceScheduler.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    static isInstance(obj: any): obj is InferenceScheduler;
    /**
     * A period of time (in minutes) by which inference on the data is delayed after the data starts.
     */
    readonly dataDelayOffsetInMinutes: pulumi.Output<number | undefined>;
    /**
     * Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location.
     */
    readonly dataInputConfiguration: pulumi.Output<outputs.lookoutequipment.DataInputConfigurationProperties>;
    /**
     * Specifies configuration information for the output results for the inference scheduler, including the S3 location for the output.
     */
    readonly dataOutputConfiguration: pulumi.Output<outputs.lookoutequipment.DataOutputConfigurationProperties>;
    /**
     * How often data is uploaded to the source S3 bucket for the input data.
     */
    readonly dataUploadFrequency: pulumi.Output<enums.lookoutequipment.InferenceSchedulerDataUploadFrequency>;
    /**
     * The Amazon Resource Name (ARN) of the inference scheduler being created.
     */
    readonly inferenceSchedulerArn: pulumi.Output<string>;
    /**
     * The name of the inference scheduler being created.
     */
    readonly inferenceSchedulerName: pulumi.Output<string | undefined>;
    /**
     * The name of the previously trained ML model being used to create the inference scheduler.
     */
    readonly modelName: pulumi.Output<string>;
    /**
     * The Amazon Resource Name (ARN) of a role with permission to access the data source being used for the inference.
     */
    readonly roleArn: pulumi.Output<string>;
    /**
     * Provides the identifier of the AWS KMS customer master key (CMK) used to encrypt inference scheduler data by Amazon Lookout for Equipment.
     */
    readonly serverSideKmsKeyId: pulumi.Output<string | undefined>;
    /**
     * Any tags associated with the inference scheduler.
     */
    readonly tags: pulumi.Output<outputs.lookoutequipment.InferenceSchedulerTag[] | undefined>;
    /**
     * Create a InferenceScheduler resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    /** @deprecated InferenceScheduler is not yet supported by AWS Native, so its creation will currently fail. Please use the classic AWS provider, if possible. */
    constructor(name: string, args: InferenceSchedulerArgs, opts?: pulumi.CustomResourceOptions);
}
/**
 * The set of arguments for constructing a InferenceScheduler resource.
 */
export interface InferenceSchedulerArgs {
    /**
     * A period of time (in minutes) by which inference on the data is delayed after the data starts.
     */
    dataDelayOffsetInMinutes?: pulumi.Input<number>;
    /**
     * Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location.
     */
    dataInputConfiguration: pulumi.Input<inputs.lookoutequipment.DataInputConfigurationPropertiesArgs>;
    /**
     * Specifies configuration information for the output results for the inference scheduler, including the S3 location for the output.
     */
    dataOutputConfiguration: pulumi.Input<inputs.lookoutequipment.DataOutputConfigurationPropertiesArgs>;
    /**
     * How often data is uploaded to the source S3 bucket for the input data.
     */
    dataUploadFrequency: pulumi.Input<enums.lookoutequipment.InferenceSchedulerDataUploadFrequency>;
    /**
     * The name of the inference scheduler being created.
     */
    inferenceSchedulerName?: pulumi.Input<string>;
    /**
     * The name of the previously trained ML model being used to create the inference scheduler.
     */
    modelName: pulumi.Input<string>;
    /**
     * The Amazon Resource Name (ARN) of a role with permission to access the data source being used for the inference.
     */
    roleArn: pulumi.Input<string>;
    /**
     * Provides the identifier of the AWS KMS customer master key (CMK) used to encrypt inference scheduler data by Amazon Lookout for Equipment.
     */
    serverSideKmsKeyId?: pulumi.Input<string>;
    /**
     * Any tags associated with the inference scheduler.
     */
    tags?: pulumi.Input<pulumi.Input<inputs.lookoutequipment.InferenceSchedulerTagArgs>[]>;
}
